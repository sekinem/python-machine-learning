{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "described-gravity",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "subtle-samba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "mnist_bldr = tfds.builder('mnist')\n",
    "mnist_bldr.download_and_prepare()\n",
    "datasets = mnist_bldr.as_dataset(shuffle_files=False)\n",
    "\n",
    "mnist_train_orig = datasets['train']\n",
    "mnist_test_orig = datasets['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "impressive-sequence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x000002B16996EEE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x000002B16996EEE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function <lambda> at 0x000002B16996EEE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x000002B169A110D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x000002B169A110D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function <lambda> at 0x000002B169A110D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "mnist_train = mnist_train_orig.map(\n",
    "    lambda item: (\n",
    "        tf.cast(item['image'], tf.float32) / 255.0,\n",
    "        tf.cast(item['label'], tf.int32)\n",
    "    )\n",
    ")\n",
    "\n",
    "mnist_test = mnist_test_orig.map(\n",
    "    lambda item: (\n",
    "        tf.cast(item['image'], tf.float32) / 255.0,\n",
    "        tf.cast(item['label'], tf.int32)\n",
    "    )\n",
    ")\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "mnist_train = mnist_train.shuffle(buffer_size=BUFFER_SIZE, reshuffle_each_iteration=False)\n",
    "\n",
    "mnist_valid = mnist_train.take(10000).batch(BATCH_SIZE)\n",
    "mnist_train = mnist_train.skip(10000).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cardiovascular-decision",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_OptionsDataset shapes: {image: (28, 28, 1), label: ()}, types: {image: tf.uint8, label: tf.int64}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "secondary-charm",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(\n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=(5, 5),\n",
    "        strides=(1, 1),\n",
    "        padding='same',\n",
    "        data_format='channels_last',\n",
    "        name='conv_1',\n",
    "        activation='relu'\n",
    "    )\n",
    ")\n",
    "model.add(\n",
    "    tf.keras.layers.MaxPool2D(\n",
    "        pool_size=(2, 2),\n",
    "        name='pool_1'\n",
    "    )\n",
    ")\n",
    "model.add(\n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=64,\n",
    "        kernel_size=(5, 5),\n",
    "        strides=(1, 1),\n",
    "        padding='same',\n",
    "        data_format='channels_last',\n",
    "        name='conv_2',\n",
    "        activation='relu'\n",
    "    )\n",
    ")\n",
    "model.add(\n",
    "    tf.keras.layers.MaxPool2D(\n",
    "        pool_size=(2, 2),\n",
    "        name='pool_2'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "identified-closure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([16, 7, 7, 64])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compute_output_shape(input_shape=(16, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "mexican-discrimination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([16, 3136])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.add(tf.keras.layers.Flatten())\n",
    "model.compute_output_shape(input_shape=(16, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "coordinated-smart",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(units=1024, name='fc_1', activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(rate=0.5))\n",
    "model.add(tf.keras.layers.Dense(units=10, name='fc_2', activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abstract-maximum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_1 (Conv2D)              (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "pool_1 (MaxPooling2D)        (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              (None, 14, 14, 64)        51264     \n",
      "_________________________________________________________________\n",
      "pool_2 (MaxPooling2D)        (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "fc_1 (Dense)                 (None, 1024)              3212288   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "fc_2 (Dense)                 (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 3,274,634\n",
      "Trainable params: 3,274,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "\n",
    "model.build(input_shape=(None, 28, 28, 1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "vocal-bennett",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "republican-pastor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "782/782 [==============================] - 81s 103ms/step - loss: 0.1461 - accuracy: 0.9547 - val_loss: 0.0518 - val_accuracy: 0.9832\n",
      "Epoch 2/20\n",
      "782/782 [==============================] - 78s 100ms/step - loss: 0.0453 - accuracy: 0.9857 - val_loss: 0.0358 - val_accuracy: 0.9880\n",
      "Epoch 3/20\n",
      "782/782 [==============================] - 76s 98ms/step - loss: 0.0308 - accuracy: 0.9897 - val_loss: 0.0436 - val_accuracy: 0.9871\n",
      "Epoch 4/20\n",
      "782/782 [==============================] - 76s 98ms/step - loss: 0.0235 - accuracy: 0.9926 - val_loss: 0.0354 - val_accuracy: 0.9891\n",
      "Epoch 5/20\n",
      "782/782 [==============================] - 73s 93ms/step - loss: 0.0184 - accuracy: 0.9939 - val_loss: 0.0596 - val_accuracy: 0.9843\n",
      "Epoch 6/20\n",
      "690/782 [=========================>....] - ETA: 7s - loss: 0.0164 - accuracy: 0.9947"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    mnist_train,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    validation_data=mnist_valid,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-portable",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
