{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "extended-seeker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Length: 1112350\n",
      "Unique Characters: 80\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "with open('../../python-machine-learning-book-3rd-edition-master/ch16/1268-0.txt', 'r', encoding='utf-8') as fp:\n",
    "    text=fp.read()\n",
    "    \n",
    "start_indx = text.find('THE MYSTERIOUS ISLAND')\n",
    "end_indx = text.find('End of the Project Gutenberg')\n",
    "\n",
    "text = text[start_indx:end_indx]\n",
    "char_set = set(text)\n",
    "print('Total Length:', len(text))\n",
    "print('Unique Characters:', len(char_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "marine-mirror",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_sorted = sorted(char_set)\n",
    "char2int = {ch:i for i,ch in enumerate(chars_sorted)}\n",
    "char_array = np.array(chars_sorted)\n",
    "\n",
    "text_encoded = np.array(\n",
    "    [char2int[ch] for ch in text],\n",
    "    dtype=np.int32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "signal-mirror",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE MYSTERIOUS       == Encoding ==>  [44 32 29  1 37 48 43 44 29 42 33 39 45 43  1]\n",
      "[33 43 36 25 38 28]  == Reverse  ==>  ISLAND\n"
     ]
    }
   ],
   "source": [
    "print(text[:15], '     == Encoding ==> ', text_encoded[:15])\n",
    "print(text_encoded[15:21], ' == Reverse  ==> ', ''.join(char_array[text_encoded[15:21]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "scheduled-metallic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 -> T\n",
      "32 -> H\n",
      "29 -> E\n",
      "1 ->  \n",
      "37 -> M\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "ds_text_encoded = tf.data.Dataset.from_tensor_slices(text_encoded)\n",
    "for ex in ds_text_encoded.take(5):\n",
    "    print(f'{ex.numpy()} -> {char_array[ex.numpy()]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "distributed-princeton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function split_input_target at 0x0000025B27C40F70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function split_input_target at 0x0000025B27C40F70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "seq_length = 40\n",
    "chunk_size = seq_length + 1\n",
    "ds_chunks = ds_text_encoded.batch(chunk_size, drop_remainder=True)\n",
    "\n",
    "def split_input_target(chunk):\n",
    "    input_seq = chunk[:-1]\n",
    "    target_seq = chunk[1:]\n",
    "    return input_seq, target_seq\n",
    "\n",
    "ds_sequences = ds_chunks.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sticky-sacramento",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Input (x): 'THE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nProduced b'\n",
      "Target (y): 'HE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nProduced by'\n",
      "\n",
      " Input (x): ' Anthony Matonak, and Trevor Carlson\\n\\n\\n\\n'\n",
      "Target (y): 'Anthony Matonak, and Trevor Carlson\\n\\n\\n\\n\\n'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for example in ds_sequences.take(2):\n",
    "    print(' Input (x):', repr(''.join(char_array[example[0].numpy()])))\n",
    "    print('Target (y):', repr(''.join(char_array[example[1].numpy()])))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "logical-photography",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "ds = ds_sequences.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "falling-diagnosis",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
    "        tf.keras.layers.LSTM(rnn_units, return_sequences=True),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "mounted-purse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 256)         20480     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, None, 512)         1574912   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, None, 80)          41040     \n",
      "=================================================================\n",
      "Total params: 1,636,432\n",
      "Trainable params: 1,636,432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "charset_size = len(char_array)\n",
    "embedding_dim = 256\n",
    "rnn_units = 512\n",
    "tf.random.set_seed(1)\n",
    "model = build_model(\n",
    "    vocab_size=charset_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "heard-beaver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "424/424 [==============================] - 214s 504ms/step - loss: 1.7791\n",
      "Epoch 2/10\n",
      "424/424 [==============================] - 199s 469ms/step - loss: 1.5263\n",
      "Epoch 3/10\n",
      "424/424 [==============================] - 197s 464ms/step - loss: 1.3944\n",
      "Epoch 4/10\n",
      "424/424 [==============================] - 198s 467ms/step - loss: 1.3183\n",
      "Epoch 5/10\n",
      "424/424 [==============================] - 197s 464ms/step - loss: 1.2679\n",
      "Epoch 6/10\n",
      "424/424 [==============================] - 196s 462ms/step - loss: 1.2308\n",
      "Epoch 7/10\n",
      "424/424 [==============================] - 208s 491ms/step - loss: 1.2008\n",
      "Epoch 8/10\n",
      "424/424 [==============================] - 212s 500ms/step - loss: 1.1759\n",
      "Epoch 9/10\n",
      "424/424 [==============================] - 210s 495ms/step - loss: 1.1545\n",
      "Epoch 10/10\n",
      "424/424 [==============================] - 199s 470ms/step - loss: 1.1349\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25b366bf100>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    ")\n",
    "model.fit(ds, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "polish-occurrence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities: [0.33333334 0.33333334 0.33333334]\n",
      "array([[0, 0, 1, 2, 0, 0, 0, 0, 1, 0, 0, 1, 0, 2, 0, 0, 2, 0, 1, 1, 2, 0,\n",
      "        2, 0, 0, 1, 2, 2, 1, 2, 0, 1, 0, 0, 1, 2, 1, 2, 1, 2, 2, 1, 2, 0,\n",
      "        2, 0, 0, 0, 1, 0, 1, 0, 2, 0, 2, 1, 0, 1, 1, 2, 1, 1, 2, 1, 0, 0,\n",
      "        2, 2, 2, 2, 2, 1, 2, 1, 2, 1, 1, 2, 2, 1, 1, 2, 1, 2, 1, 2, 2, 0,\n",
      "        0, 2, 2, 1, 2, 0, 1, 2, 2, 1, 2, 0]], dtype=int64)\r\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "\n",
    "logits = [[1.0, 1.0, 1.0]]\n",
    "print('Probabilities:', tf.math.softmax(logits).numpy()[0])\n",
    "\n",
    "samples = tf.random.categorical(logits=logits, num_samples=100)\n",
    "tf.print(samples.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "quiet-planet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities: [9.1022195e-04 9.1022195e-04 9.9817955e-01]\n",
      "array([[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]], dtype=int64)\r\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "\n",
    "logits = [[1.0, 1.0, 8.0]]\n",
    "print('Probabilities:', tf.math.softmax(logits).numpy()[0])\n",
    "\n",
    "samples = tf.random.categorical(logits=logits, num_samples=100)\n",
    "tf.print(samples.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "convertible-concord",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(model, starting_str, len_generated_text=500, max_input_length=40, scale_factor=1.0):\n",
    "    encoded_input = [char2int[s] for s in starting_str]\n",
    "    encoded_input = tf.reshape(encoded_input, (1, -1))\n",
    "\n",
    "    generated_str = starting_str\n",
    "\n",
    "    model.reset_states()\n",
    "    for i in range(len_generated_text):\n",
    "        logits = model(encoded_input)\n",
    "        logits = tf.squeeze(logits, 0)\n",
    "\n",
    "        scaled_logits = logits * scale_factor\n",
    "        new_char_indx = tf.random.categorical(\n",
    "            scaled_logits, num_samples=1)\n",
    "        \n",
    "        new_char_indx = tf.squeeze(new_char_indx)[-1].numpy()    \n",
    "\n",
    "        generated_str += str(char_array[new_char_indx])\n",
    "        \n",
    "        new_char_indx = tf.expand_dims([new_char_indx], 0)\n",
    "        encoded_input = tf.concat(\n",
    "            [encoded_input, new_char_indx],\n",
    "            axis=1\n",
    "        )\n",
    "        encoded_input = encoded_input[:, -max_input_length:]\n",
    "\n",
    "    return generated_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "young-newport",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The island is probable that the viewing from he smilfrals continued; but it would inhabited to get complete some condition; it was completely two cape birds. It was\n",
      "agreed that\n",
      "they had suffended from the mountain.\n",
      "\n",
      "Now, he\n",
      "is not the damo, them is his possessioned no gotallets, and it was necessary to give under the\n",
      "Chimneys.\n",
      "\n",
      "All these teights whomselves in\n",
      "branches, during these restering pur.\n",
      "If greatly cleared from a tonn his hopes, moon had disasperied eight themselves out in the baulist,\n",
      "pearance, \n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "\n",
    "print(sample(model, starting_str='The island'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "moderate-patio",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The island was so as to make a sufficient to search the sailor.\n",
      "\n",
      "“We must there!”\n",
      "\n",
      "“That is to say, the colonists the settlers were the corral, had been able to the corral and all the river, and they had not appeared to the\n",
      "corral which formed the protection of the island, which he entirely came to the corral!\n",
      "\n",
      "“We shall be a man go the subjection, to the shore, or the corral, who had been convicts were to be done but to return to the southern plants, and the captain was of the lake. The wind had already \n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "\n",
    "print(sample(model, starting_str='The island', scale_factor=2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "excited-freight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The island hanging he drefude? Top wished-from\n",
      "Granfop.\n",
      "PEbintiNausualavting-yig. The\n",
      "Crinces: I knew solid morig, if upberreps. He saw, I hasty, a labaphirrihuly?”\n",
      "\n",
      "When Captain\n",
      "Surior,” me amugiluzage.”\n",
      "\n",
      "Wiir torce?” mumb\n",
      "all,” asked Captajt to their, broke: better certain, pieces it?”\n",
      "\n",
      "“STance!” exited. Luid\n",
      "it cod incandanc,\n",
      "a misery.”\n",
      "\n",
      "At thisfi’k,”\n",
      "said\n",
      "Gideon. To worting. “Cape, greshnewi8-qoight,”.\n",
      "\n",
      "For. In cqusy griet, duriousnets,\n",
      "Pencrofts wassigake,\n",
      "coptaless, carmlured useff.”\n",
      "\n",
      "Lonag?\n",
      "a8rror \n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "\n",
    "print(sample(model, starting_str='The island', scale_factor=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-scientist",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
